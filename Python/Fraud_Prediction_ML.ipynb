{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 4 - Fraud Prediction:"
      ],
      "metadata": {
        "id": "lBWe2PxpfDSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727QkM74fJwV",
        "outputId": "6286bcbc-b5f1-46bd-f3b8-040e5f85eb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in the Test and Train Set's:"
      ],
      "metadata": {
        "id": "e1hQn7B7fS4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load in testa nd train data\n",
        "train_df = pd.read_csv('/content/drive/My Drive/training.csv', delimiter = ',', encoding = 'ISO-8859-1')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/test.csv', delimiter = ',', encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "fs-is5RUfW56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA and preparation for training:"
      ],
      "metadata": {
        "id": "lvtdg5ho4iVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop columns with too many missing values\n",
        "train_df = train_df.drop(['ANUMBER_02', 'ANUMBER_03', 'ANUMBER_04', 'ANUMBER_05'], axis=1)\n",
        "test_df = test_df.drop(['ANUMBER_02', 'ANUMBER_03', 'ANUMBER_04', 'ANUMBER_05'], axis=1)\n",
        "\n",
        "#Encode categorial features\n",
        "le = LabelEncoder()\n",
        "categorial_features = ['O_EMAIL', 'O_TELEPHONE', 'FLAG_DIIDENTICAL', 'FLAG_NEWSLETTER', \n",
        "              'CHK_LADR', 'CHK_RADR', 'CHK_KTO', 'CHK_CARD', 'CHK_COOKIE', \n",
        "              'CHK_IP', 'FAIL_LPLZ', 'FAIL_LORT', 'FAIL_LPLZORTMATCH', \n",
        "              'FAIL_RPLZ', 'FAIL_RORT', 'FAIL_RPLZORTMATCH', 'NEW_CUSTOMER', \n",
        "              'P_METHOD','P_CARD_TYPE', 'DEL_DAY', 'P_METHOD', 'P_CARD_TYPE', \n",
        "              'DEL_DAY']\n",
        "\n",
        "for feature in categorial_features:\n",
        "  train_df[feature] = le.fit_transform(train_df[feature])\n",
        "  test_df[feature] = le.fit_transform(test_df[feature])\n",
        "\n",
        "#Replace NaN values in 'REM_CUR' and 'REM_MAX' for better learning\n",
        "\n",
        "train_df[['REM_CUR', 'REM_MAX']] = train_df[['REM_CUR', 'REM_MAX']].fillna(0.0)\n",
        "test_df[['REM_CUR', 'REM_MAX']] = test_df[['REM_CUR', 'REM_MAX']].fillna(0.0)\n",
        "\n",
        "#Check fi their are NaN values\n",
        "print(train_df.isna().sum())"
      ],
      "metadata": {
        "id": "zXmaoT7I4nDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Create new features:"
      ],
      "metadata": {
        "id": "mY__EfRR4nqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Feature 'DEL_AMOUNT_DIFF':"
      ],
      "metadata": {
        "id": "yYqqQLlH9uOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new feature 'DEL_AMOUNT_DIFF' which is the 'DEL_AMOUNT' minus it's mean\n",
        "train_df['DEL_AMOUNT_DIFF'] = train_df['DEL_AMOUNT'] - train_df['DEL_AMOUNT'].mean()\n",
        "test_df['DEL_AMOUNT_DIFF'] = test_df['DEL_AMOUNT'] - test_df['DEL_AMOUNT'].mean()"
      ],
      "metadata": {
        "id": "fhqWax7ujfLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "\n",
        "The new feature 'DEL_AMOUNT_DIFF' represents the difference between the 'DEL_AMOUNT' value to the mean. This feature can help to improve the performance, because it shows how much this order deviates from the average, which could be related to the likelihood of a customer to pay."
      ],
      "metadata": {
        "id": "VEzAI_pN9zUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Feature 'DEL_VALUE_DIFF'"
      ],
      "metadata": {
        "id": "141Xblfi_TSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new feature 'DEL_VALUE_DIFF' which is the 'DEL_VALUE' minus it's mean\n",
        "train_df['DEL_VALUE_DIFF'] = train_df['DEL_VALUE'] - train_df['DEL_VALUE'].mean()\n",
        "test_df['DEL_VALUE_DIFF'] = test_df['DEL_VALUE'] - test_df['DEL_VALUE'].mean()"
      ],
      "metadata": {
        "id": "WJwzirchjgr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description: \n",
        "\n",
        "The new feature 'DEL_AMOUNT_DIFF' represents the differnce in a specific order compared to the mean. It can help to improve the performance of the model, because it shows how much a specific order varies from the average order. This could be related to the likelihood of a customer to pay."
      ],
      "metadata": {
        "id": "WgwBk5SP_2kS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature: 'SESSION_TIME_DIFF'"
      ],
      "metadata": {
        "id": "dwLE5FRPAV4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new feature 'SESSION_TIME_DIFF' which is the 'SESSION_TIME' minus it's mean\n",
        "train_df['SESSION_TIME_DIFF'] = train_df['SESSION_TIME'] - train_df['SESSION_TIME'].mean()\n",
        "test_df['SESSION_TIME_DIFF'] = test_df['SESSION_TIME'] - test_df['SESSION_TIME'].mean()"
      ],
      "metadata": {
        "id": "3Dti8jSHjg1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "\n",
        "The new feature 'SESSION_TIME_DIFF' compares this orders session time to the average. This can help to see if orders went way faster or slower then usual, which can may relate to customers make to quick choices in their orders or picked the items very carefully."
      ],
      "metadata": {
        "id": "QSKAJBYICqlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Feature 'VALUE_AMOUNT_CMP'"
      ],
      "metadata": {
        "id": "4_08c-wQDXUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new feature 'VALUE_AMOUNT_CMP' this compares this ordes value per item average to the general value per item average of this customer\n",
        "train_df['VALUE_AMOUNT_CMP'] = (train_df['DEL_VALUE'] / train_df['DEL_AMOUNT']) - (train_df['DEL_VALUE_TOTAL'] / train_df['DEL_AMOUNT_TOTAL'])\n",
        "test_df['VALUE_AMOUNT_CMP'] = (test_df['DEL_VALUE'] / test_df['DEL_AMOUNT']) - (test_df['DEL_VALUE_TOTAL'] / test_df['DEL_AMOUNT_TOTAL'])\n",
        "\n",
        "\n",
        "#Handle NaN values based on 'DEL_AMOUNT_TOTAL' being zero or 'DEL_VALUE_TOTAL' being zero\n",
        "train_df['VALUE_AMOUNT_CMP'] = train_df['VALUE_AMOUNT_CMP'].fillna(train_df['DEL_VALUE'] / train_df['DEL_AMOUNT'])\n",
        "test_df['VALUE_AMOUNT_CMP'] = test_df['VALUE_AMOUNT_CMP'].fillna(test_df['DEL_VALUE'] / test_df['DEL_AMOUNT'])"
      ],
      "metadata": {
        "id": "G5PtiuIehJ73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "\n",
        "The new feature 'VALUE_AMOUNT_CMP' compares this orders average value per item to the average value per item of this customer in general. This can help to identify any anomalous behaviour which could indicate fraud. So this new feature can help to improve the performance at predicting fraud."
      ],
      "metadata": {
        "id": "IkwNc_bJFbIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create test and train sets:"
      ],
      "metadata": {
        "id": "5bKlr03QF8zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create test and train sets\n",
        "X_train = train_df.drop(['TARGET_FRAUD'], axis=1)\n",
        "y_train = train_df['TARGET_FRAUD']\n",
        "X_test = test_df"
      ],
      "metadata": {
        "id": "XQGn55rnG20L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning:"
      ],
      "metadata": {
        "id": "I9yaCJcCHaPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to tune\n",
        "#hyperparameters = {\n",
        "    #'penalty': ['l1', 'l2'],\n",
        "    #'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    #'solver': ['liblinear']\n",
        "#}\n",
        "\n",
        "# Initialize the model\n",
        "#model = LogisticRegression()\n",
        "\n",
        "# Use GridSearchCV to tune the hyperparameters\n",
        "#grid_search = GridSearchCV(model, hyperparameters, scoring='roc_auc', cv=5)\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "#print(f'Best hyperparameters: {grid_search.best_params_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15t1pY_0HaaS",
        "outputId": "316ccfd6-174c-42bb-ac37-c90a938f3945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result:"
      ],
      "metadata": {
        "id": "p8JHqp24Ra_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the model\n",
        "model = LogisticRegression(C = 100, penalty = 'l1', solver = 'liblinear')\n",
        "\n",
        "#fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "test_df['prediction'] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "#Create csv\n",
        "test_df[['Id', 'prediction']].to_csv('predictions_target_fraud.csv', index = False) "
      ],
      "metadata": {
        "id": "n25j0qWKReEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}